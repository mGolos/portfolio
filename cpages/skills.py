import streamlit as st
from tools import utils
sss = st.session_state


def main():
    dico = {
        (
                "üìù **Programming / Collaboration**",
                "üìù **Programmation / Collaboration**",
            ): {
            ("Languages", "Langages"): "`Python, SQL, Bash, Shell, MATLAB`",
            ("Environments", "Environnements"): "`VS Code, Jupyter Notebooks, Deepnote, Google Colab, Kaggle, Python Anywhere`",
            ("Package Management", "Gestion des Packages"): "`Pip, Anaconda, Virtualenv`",
            ("Testing Frameworks", "Frameworks de Test"): "`PyTest, Unittest`",
            ("Version Control", "Contr√¥le de Version"): "`Git, GitHub, GitLab, Bitbucket`",
            ("Collaboration Tools", "Outils de Collaboration"): "`Jira, Trello, Slack, Teams, Markdown, Confluence, Office, LaTeX`",
            ("Operating System", "Syst√®me d'exploitation"): "`Windows, Linux (Debian, CentOs, Ubuntu), macOS`",
        },
        (
                "üìä **Analysis / Data Visualization**",
                "üìä **Analyse / Visualisation de donn√©es**",
            ): {
            ("Python", "Python"): "`Pandas, NumPy, Matplotlib, Seaborn, Plotly`",
            ("Excel", "Excel"): "`Advanced Functions, Pivot Tables, VBA`",
            ("BI Tools", "Outils BI"): "`Tableau, Power BI, Dash, Streamlit, Xmind, Gephi`",
            ("Significance Testing", "Test de Signification"): "`dummy, baseline, a priori, p-values, Confidence Intervals`",
            ("Hypothesis Testing", "Test d'Hypoth√®se"): "`t-tests, ANOVA, Chi-Square Test`",
            ("Statistical Modeling", "Mod√©lisation Statistique"): "`Time Series Analysis, Bayesian Inference, Regression, Probability Distributions`",
            ("Wrangling & Cleaning", "Nettoyage et Transformation"): "`Missing data handling, Outliers, Feature engineering, PCA, UMAP`",
            ("Model Evaluation", "√âvaluation de Mod√®le"): "`Cross-validation, Confusion Matrix, ROC-AUC, Precision-Recall, F1 Score`",
        },
        (
                "ü§ñ **Machine Learning / NLP**",
                "ü§ñ **Machine Learning / NLP**",
            ): {
            ("Frameworks", "Frameworks"): "`Scikit-learn, TensorFlow, Keras, PyTorch`",
            ("Libraries", "Biblioth√®ques"): "`NLTK, SpaCy, Hugging Face Transformers, PIL, Scikit-image, BeautifulSoup`",
            ("Supervised Learning", "Apprentissage Supervis√©"): "`Linear Regression, Logistic Regression, SVMs, Decision Trees, Random Forests, k-NN`",
            ("Unsupervised Learning", "Apprentissage Non Supervis√©"): "`K-Means, PCA, DBSCAN`",
            ("Deep Learning", "Apprentissage Profond"): "`Neural Networks, CNNs, RNNs, Transfer Learning`",
            ("Text Processing", "Traitement de Texte"): "`Tokenization, Lemmatization, Stemming, Stopword Removal, Word2Vec`",
            ("Model Tuning", "Ajustement de Mod√®le"): "`Grid Search, Random Search, Hyperparameter Optimization, TPOT`",
            ("Optimization Methods", "M√©thodes d'Optimisation"): "`Gradient Descent, Genetic Algorithms`",
        },
        (
                "üõ†Ô∏è **DevOps / Data Engineering / Deployment**",
                "üõ†Ô∏è **DevOps / Data Engineering / D√©ploiement**",
            ): {
            ("APIs for Deployment", "APIs pour D√©ploiement"): "`Flask, FastAPI, Django REST Framework`",
            ("CI/CD", "CI/CD"): "`GitLab CI, GitHub Actions, Jenkins`",
            ("Cloud Platforms", "Plateformes Cloud"): "`AWS, GCP, Microsoft Azure`",
            ("Containerization & Orchestration", "Containerisation & Orchestration"): "`Docker, Kubernetes, Prefect`",
            ("Serverless", "Serverless"): "`AWS Lambda, Google Cloud Functions, Azure Functions`",
            ("Databases", "Bases de Donn√©es"): "`MySQL, PostgreSQL, SQLite, MongoDB, Redis`",
            ("Monitoring", "Surveillance"): "`Prometheus, Grafana, MLFlow`",
        },
    }
    func_skills = {
        "name": (
            "üß© **Functional Skills**",
            "üß© **Comp√©tences Fonctionnelles**"),
        "description": (
            """
            * Problem identification & Functional needs analysis
            * Solution planning
            * Exploratory analysis & Conceptual and analytical vision
            * Data modeling and transformation for exploitation
            * Creation of tools for data processing and visualizations
            * Resolution of complex business problems
            * Application of state-of-the-art in the field
            * Critical thinking and scientific rigor
            * Ensuring responsibility for one or more functional processes
            """,
            """
            * Identification des probl√®mes & Analyse fonctionnelle des besoins
            * Planification des solutions
            * Analyse exploratoire & Vision analytique et conceptuelle
            * Mod√©lisation et transformation des donn√©es pour exploitation
            * Cr√©ation d‚Äôoutils de traitements de donn√©es et de visualisations
            * R√©solution de probl√©matiques m√©tiers complexes
            * Application de l‚Äô√©tat de l‚Äôart du domaine
            * Raisonnement critique et rigueur scientifique
            * Assurer la responsabilit√© d'un ou plusieurs processus fonctionnels
            """),
    }

    st.header(
        "Comp√©tences" if sss["lg_key"] else 'Hard Skills', 
        anchor='skills', divider="orange")
        
    for exp, sub in dico.items():
        with st.expander(exp[sss["lg_key"]], expanded=False):
            for k, v in sub.items():
                if sss['layout'] == "wide":
                    st.write(" : ".join([k[sss["lg_key"]], v]))
                else:
                    cs = st.columns([1,3])
                    cs[0].write(k[sss["lg_key"]])
                    cs[1].write(v)
    
    with st.expander(func_skills['name'][sss["lg_key"]], expanded=False):
        st.write(func_skills['description'][sss["lg_key"]])
    

if __name__ == "__main__":
    utils.always()
    main()
    utils.footer()
    utils.background()
